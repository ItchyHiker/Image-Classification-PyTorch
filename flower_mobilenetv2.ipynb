{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sZ_gqIz3EMI9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torch.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchsummary import summary\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from nets.mobilenet_v2 import MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2uhcREHhKW4x"
   },
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/ubuntu/dataset/flower_photos/'\n",
    "train_data_path = '/home/ubuntu/dataset/flower_photos/train'\n",
    "val_data_path = '/home/ubuntu/dataset/flower_photos/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tetB5zyfRKeU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 2934\n",
      "Number of validation samples: 736\n",
      "samples per class: {0: 506, 1: 718, 2: 512, 3: 559, 4: 639}\n",
      "class_weights for each class: [1.4189723320158103, 1.0, 1.40234375, 1.2844364937388193, 1.1236306729264476]\n"
     ]
    }
   ],
   "source": [
    "train_data_transforms = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.516, 0.459, 0.434], [0.278, 0.261, 0.257])\n",
    "    ])\n",
    "val_data_transforms = transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.516, 0.459, 0.434], [0.278, 0.261, 0.257])\n",
    "    ])\n",
    "\n",
    "train_image_dataset = datasets.ImageFolder(train_data_path, train_data_transforms)\n",
    "train_data_loader = torch.utils.data.DataLoader(train_image_dataset, batch_size=32, shuffle=True, num_workers=2, )\n",
    "dataset_size = len(train_image_dataset)\n",
    "\n",
    "val_image_dataset = datasets.ImageFolder(val_data_path, val_data_transforms)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_image_dataset, batch_size=32, shuffle=True, num_workers=2, )\n",
    "\n",
    "class_counts = dict(Counter(sample_tup[1] for sample_tup in train_image_dataset.imgs))\n",
    "class_weights = [1-(float(class_counts[class_id])/(dataset_size)) for class_id in range(5)]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_image_dataset))\n",
    "print(\"Number of validation samples:\", len(val_image_dataset))\n",
    "\n",
    "print(\"samples per class:\", class_counts)\n",
    "max_val = float(max(class_counts.values()))\n",
    "class_weights = [max_val/num_images for class_id, num_images in class_counts.items()]\n",
    "print(\"class_weights for each class:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OOyLe1sPz6ke"
   },
   "source": [
    "## Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3IbfN2Skz96y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 16, 112, 112]             512\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
      "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
      "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
      "            ReLU6-12         [-1, 96, 112, 112]               0\n",
      "           Conv2d-13           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
      "            ReLU6-15           [-1, 96, 56, 56]               0\n",
      "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
      "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
      "            ReLU6-21          [-1, 144, 56, 56]               0\n",
      "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
      "            ReLU6-24          [-1, 144, 56, 56]               0\n",
      "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
      "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
      "            ReLU6-30          [-1, 144, 56, 56]               0\n",
      "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
      "            ReLU6-33          [-1, 144, 28, 28]               0\n",
      "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
      "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
      "            ReLU6-39          [-1, 192, 28, 28]               0\n",
      "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
      "            ReLU6-42          [-1, 192, 28, 28]               0\n",
      "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
      "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
      "            ReLU6-48          [-1, 192, 28, 28]               0\n",
      "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
      "            ReLU6-51          [-1, 192, 28, 28]               0\n",
      "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
      "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
      "            ReLU6-57          [-1, 192, 28, 28]               0\n",
      "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
      "            ReLU6-60          [-1, 192, 14, 14]               0\n",
      "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
      "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
      "            ReLU6-66          [-1, 384, 14, 14]               0\n",
      "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
      "            ReLU6-69          [-1, 384, 14, 14]               0\n",
      "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
      "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
      "            ReLU6-75          [-1, 384, 14, 14]               0\n",
      "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
      "            ReLU6-78          [-1, 384, 14, 14]               0\n",
      "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
      "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
      "            ReLU6-84          [-1, 384, 14, 14]               0\n",
      "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
      "            ReLU6-87          [-1, 384, 14, 14]               0\n",
      "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
      "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
      "            ReLU6-93          [-1, 384, 14, 14]               0\n",
      "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
      "            ReLU6-96          [-1, 384, 14, 14]               0\n",
      "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
      " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
      "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-102          [-1, 576, 14, 14]               0\n",
      "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-105          [-1, 576, 14, 14]               0\n",
      "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
      "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-111          [-1, 576, 14, 14]               0\n",
      "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-114          [-1, 576, 14, 14]               0\n",
      "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
      "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-120          [-1, 576, 14, 14]               0\n",
      "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
      "           ReLU6-123            [-1, 576, 7, 7]               0\n",
      "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
      "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-129            [-1, 960, 7, 7]               0\n",
      "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-132            [-1, 960, 7, 7]               0\n",
      "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
      "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-138            [-1, 960, 7, 7]               0\n",
      "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-141            [-1, 960, 7, 7]               0\n",
      "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
      "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-147            [-1, 960, 7, 7]               0\n",
      "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-150            [-1, 960, 7, 7]               0\n",
      "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
      "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
      "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
      "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
      "       AvgPool2d-157           [-1, 1280, 1, 1]               0\n",
      "         Dropout-158                 [-1, 1280]               0\n",
      "          Linear-159                    [-1, 5]           6,405\n",
      "         Softmax-160                    [-1, 5]               0\n",
      "================================================================\n",
      "Total params: 2,230,277\n",
      "Trainable params: 2,230,277\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 152.87\n",
      "Params size (MB): 8.51\n",
      "Estimated Total Size (MB): 161.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "lr = 1e-3\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).cuda())\n",
    "base_model = MobileNetV2()\n",
    "base_model.load_state_dict(torch.load('models/mobilenet_v2.pth.tar'), strict=False)\n",
    "model = base_model\n",
    "model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(model.last_channel, 5),\n",
    "    )\n",
    "summary(model.cuda(), (3, 224, 224))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "lr_scheduler = MultiStepLR(optimizer, milestones=[80, 160], gamma=0.1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "show_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACbdllLK0JS5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:000 lr: 0.001000 Step:0000 Train Loss: 1.630167 Train Accuracy: 0.156250\n",
      "Epoch:000 lr: 0.001000 Step:0050 Train Loss: 1.201343 Train Accuracy: 0.705882\n",
      "Epoch:000 Test Loss: 1.122704 Test Accuracy: 0.777174\n",
      "Epoch:001 lr: 0.001000 Step:0000 Train Loss: 1.265254 Train Accuracy: 0.656250\n",
      "Epoch:001 lr: 0.001000 Step:0050 Train Loss: 1.188767 Train Accuracy: 0.707108\n",
      "Epoch:001 Test Loss: 1.133944 Test Accuracy: 0.767663\n",
      "Epoch:002 lr: 0.001000 Step:0000 Train Loss: 1.162206 Train Accuracy: 0.718750\n",
      "Epoch:002 lr: 0.001000 Step:0050 Train Loss: 1.131895 Train Accuracy: 0.770221\n",
      "Epoch:002 Test Loss: 1.092053 Test Accuracy: 0.797554\n",
      "Epoch:003 lr: 0.001000 Step:0000 Train Loss: 1.149212 Train Accuracy: 0.750000\n",
      "Epoch:003 lr: 0.001000 Step:0050 Train Loss: 1.152928 Train Accuracy: 0.751225\n",
      "Epoch:003 Test Loss: 1.083777 Test Accuracy: 0.811141\n",
      "Epoch:004 lr: 0.001000 Step:0000 Train Loss: 1.149331 Train Accuracy: 0.750000\n",
      "Epoch:004 lr: 0.001000 Step:0050 Train Loss: 1.146863 Train Accuracy: 0.753676\n",
      "Epoch:004 Test Loss: 1.074936 Test Accuracy: 0.828804\n",
      "Epoch:005 lr: 0.001000 Step:0000 Train Loss: 1.105768 Train Accuracy: 0.812500\n",
      "Epoch:005 lr: 0.001000 Step:0050 Train Loss: 1.130968 Train Accuracy: 0.769608\n",
      "Epoch:005 Test Loss: 1.091423 Test Accuracy: 0.822011\n",
      "Epoch:006 lr: 0.001000 Step:0000 Train Loss: 0.948407 Train Accuracy: 0.937500\n",
      "Epoch:006 lr: 0.001000 Step:0050 Train Loss: 1.119624 Train Accuracy: 0.784314\n",
      "Epoch:006 Test Loss: 1.065207 Test Accuracy: 0.827446\n",
      "Epoch:007 lr: 0.001000 Step:0000 Train Loss: 1.064614 Train Accuracy: 0.843750\n",
      "Epoch:007 lr: 0.001000 Step:0050 Train Loss: 1.118588 Train Accuracy: 0.783701\n",
      "Epoch:007 Test Loss: 1.082685 Test Accuracy: 0.822011\n",
      "Epoch:008 lr: 0.001000 Step:0000 Train Loss: 1.116170 Train Accuracy: 0.781250\n",
      "Epoch:008 lr: 0.001000 Step:0050 Train Loss: 1.096472 Train Accuracy: 0.809436\n",
      "Epoch:008 Test Loss: 1.075072 Test Accuracy: 0.832880\n",
      "Epoch:009 lr: 0.001000 Step:0000 Train Loss: 1.084008 Train Accuracy: 0.812500\n",
      "Epoch:009 lr: 0.001000 Step:0050 Train Loss: 1.108790 Train Accuracy: 0.794118\n",
      "Epoch:009 Test Loss: 1.075792 Test Accuracy: 0.828804\n",
      "Epoch:010 lr: 0.001000 Step:0000 Train Loss: 1.141587 Train Accuracy: 0.718750\n",
      "Epoch:010 lr: 0.001000 Step:0050 Train Loss: 1.128448 Train Accuracy: 0.772059\n",
      "Epoch:010 Test Loss: 1.030007 Test Accuracy: 0.869565\n",
      "Epoch:011 lr: 0.001000 Step:0000 Train Loss: 1.291101 Train Accuracy: 0.593750\n",
      "Epoch:011 lr: 0.001000 Step:0050 Train Loss: 1.087505 Train Accuracy: 0.815564\n",
      "Epoch:011 Test Loss: 1.035582 Test Accuracy: 0.873641\n",
      "Epoch:012 lr: 0.001000 Step:0000 Train Loss: 0.978075 Train Accuracy: 0.937500\n",
      "Epoch:012 lr: 0.001000 Step:0050 Train Loss: 1.062581 Train Accuracy: 0.840686\n",
      "Epoch:012 Test Loss: 1.228120 Test Accuracy: 0.673913\n",
      "Epoch:013 lr: 0.001000 Step:0000 Train Loss: 1.064922 Train Accuracy: 0.843750\n",
      "Epoch:013 lr: 0.001000 Step:0050 Train Loss: 1.095298 Train Accuracy: 0.809436\n",
      "Epoch:013 Test Loss: 1.074836 Test Accuracy: 0.824728\n",
      "Epoch:014 lr: 0.001000 Step:0000 Train Loss: 1.171013 Train Accuracy: 0.750000\n",
      "Epoch:014 lr: 0.001000 Step:0050 Train Loss: 1.113246 Train Accuracy: 0.791667\n",
      "Epoch:014 Test Loss: 1.080885 Test Accuracy: 0.823370\n",
      "Epoch:015 lr: 0.001000 Step:0000 Train Loss: 1.089109 Train Accuracy: 0.812500\n",
      "Epoch:015 lr: 0.001000 Step:0050 Train Loss: 1.080101 Train Accuracy: 0.824142\n",
      "Epoch:015 Test Loss: 1.063222 Test Accuracy: 0.838315\n",
      "Epoch:016 lr: 0.001000 Step:0000 Train Loss: 1.009549 Train Accuracy: 0.906250\n",
      "Epoch:016 lr: 0.001000 Step:0050 Train Loss: 1.080887 Train Accuracy: 0.822917\n",
      "Epoch:016 Test Loss: 1.116161 Test Accuracy: 0.796196\n",
      "Epoch:017 lr: 0.001000 Step:0000 Train Loss: 0.994381 Train Accuracy: 0.906250\n",
      "Epoch:017 lr: 0.001000 Step:0050 Train Loss: 1.077264 Train Accuracy: 0.824755\n",
      "Epoch:017 Test Loss: 1.051654 Test Accuracy: 0.849185\n",
      "Epoch:018 lr: 0.001000 Step:0000 Train Loss: 1.103983 Train Accuracy: 0.812500\n",
      "Epoch:018 lr: 0.001000 Step:0050 Train Loss: 1.089464 Train Accuracy: 0.813725\n",
      "Epoch:018 Test Loss: 1.056433 Test Accuracy: 0.847826\n",
      "Epoch:019 lr: 0.001000 Step:0000 Train Loss: 1.067766 Train Accuracy: 0.812500\n",
      "Epoch:019 lr: 0.001000 Step:0050 Train Loss: 1.082123 Train Accuracy: 0.822304\n",
      "Epoch:019 Test Loss: 1.032985 Test Accuracy: 0.869565\n",
      "Epoch:020 lr: 0.001000 Step:0000 Train Loss: 1.028321 Train Accuracy: 0.875000\n",
      "Epoch:020 lr: 0.001000 Step:0050 Train Loss: 1.085301 Train Accuracy: 0.814951\n",
      "Epoch:020 Test Loss: 1.039967 Test Accuracy: 0.862772\n",
      "Epoch:021 lr: 0.001000 Step:0000 Train Loss: 1.057230 Train Accuracy: 0.843750\n",
      "Epoch:021 lr: 0.001000 Step:0050 Train Loss: 1.063664 Train Accuracy: 0.841912\n",
      "Epoch:021 Test Loss: 1.067406 Test Accuracy: 0.828804\n",
      "Epoch:022 lr: 0.001000 Step:0000 Train Loss: 1.138135 Train Accuracy: 0.750000\n",
      "Epoch:022 lr: 0.001000 Step:0050 Train Loss: 1.080794 Train Accuracy: 0.819240\n",
      "Epoch:022 Test Loss: 1.065283 Test Accuracy: 0.831522\n",
      "Epoch:023 lr: 0.001000 Step:0000 Train Loss: 1.037597 Train Accuracy: 0.875000\n",
      "Epoch:023 lr: 0.001000 Step:0050 Train Loss: 1.083730 Train Accuracy: 0.819853\n",
      "Epoch:023 Test Loss: 1.050503 Test Accuracy: 0.860054\n",
      "Epoch:024 lr: 0.001000 Step:0000 Train Loss: 1.016305 Train Accuracy: 0.906250\n",
      "Epoch:024 lr: 0.001000 Step:0050 Train Loss: 1.086110 Train Accuracy: 0.813725\n",
      "Epoch:024 Test Loss: 1.077316 Test Accuracy: 0.820652\n",
      "Epoch:025 lr: 0.001000 Step:0000 Train Loss: 0.966083 Train Accuracy: 0.937500\n",
      "Epoch:025 lr: 0.001000 Step:0050 Train Loss: 1.073383 Train Accuracy: 0.826593\n",
      "Epoch:025 Test Loss: 1.047609 Test Accuracy: 0.855978\n",
      "Epoch:026 lr: 0.001000 Step:0000 Train Loss: 1.097150 Train Accuracy: 0.812500\n",
      "Epoch:026 lr: 0.001000 Step:0050 Train Loss: 1.097236 Train Accuracy: 0.805147\n",
      "Epoch:026 Test Loss: 1.060900 Test Accuracy: 0.841033\n",
      "Epoch:027 lr: 0.001000 Step:0000 Train Loss: 1.036059 Train Accuracy: 0.875000\n",
      "Epoch:027 lr: 0.001000 Step:0050 Train Loss: 1.123833 Train Accuracy: 0.775123\n",
      "Epoch:027 Test Loss: 1.040252 Test Accuracy: 0.858696\n",
      "Epoch:028 lr: 0.001000 Step:0000 Train Loss: 1.135136 Train Accuracy: 0.781250\n",
      "Epoch:028 lr: 0.001000 Step:0050 Train Loss: 1.074921 Train Accuracy: 0.825980\n",
      "Epoch:028 Test Loss: 1.062369 Test Accuracy: 0.835598\n",
      "Epoch:029 lr: 0.001000 Step:0000 Train Loss: 1.144736 Train Accuracy: 0.750000\n",
      "Epoch:029 lr: 0.001000 Step:0050 Train Loss: 1.084530 Train Accuracy: 0.814951\n",
      "Epoch:029 Test Loss: 1.044407 Test Accuracy: 0.862772\n",
      "Epoch:030 lr: 0.001000 Step:0000 Train Loss: 1.076033 Train Accuracy: 0.875000\n",
      "Epoch:030 lr: 0.001000 Step:0050 Train Loss: 1.039888 Train Accuracy: 0.864583\n",
      "Epoch:030 Test Loss: 1.048913 Test Accuracy: 0.849185\n",
      "Epoch:031 lr: 0.001000 Step:0000 Train Loss: 1.083273 Train Accuracy: 0.843750\n",
      "Epoch:031 lr: 0.001000 Step:0050 Train Loss: 1.056135 Train Accuracy: 0.846201\n",
      "Epoch:031 Test Loss: 1.081956 Test Accuracy: 0.811141\n",
      "Epoch:032 lr: 0.001000 Step:0000 Train Loss: 1.129273 Train Accuracy: 0.781250\n",
      "Epoch:032 lr: 0.001000 Step:0050 Train Loss: 1.070712 Train Accuracy: 0.825980\n",
      "Epoch:032 Test Loss: 1.034428 Test Accuracy: 0.869565\n",
      "Epoch:033 lr: 0.001000 Step:0000 Train Loss: 1.162582 Train Accuracy: 0.750000\n",
      "Epoch:033 lr: 0.001000 Step:0050 Train Loss: 1.061786 Train Accuracy: 0.841912\n",
      "Epoch:033 Test Loss: 1.028851 Test Accuracy: 0.870924\n",
      "Epoch:034 lr: 0.001000 Step:0000 Train Loss: 1.004931 Train Accuracy: 0.906250\n",
      "Epoch:034 lr: 0.001000 Step:0050 Train Loss: 1.066491 Train Accuracy: 0.832108\n",
      "Epoch:034 Test Loss: 1.030322 Test Accuracy: 0.872283\n",
      "Epoch:035 lr: 0.001000 Step:0000 Train Loss: 1.117254 Train Accuracy: 0.781250\n",
      "Epoch:035 lr: 0.001000 Step:0050 Train Loss: 1.070181 Train Accuracy: 0.832108\n",
      "Epoch:035 Test Loss: 1.063368 Test Accuracy: 0.842391\n",
      "Epoch:036 lr: 0.001000 Step:0000 Train Loss: 0.973008 Train Accuracy: 0.937500\n",
      "Epoch:036 lr: 0.001000 Step:0050 Train Loss: 1.059990 Train Accuracy: 0.843137\n",
      "Epoch:036 Test Loss: 1.037254 Test Accuracy: 0.862772\n",
      "Epoch:037 lr: 0.001000 Step:0000 Train Loss: 0.963350 Train Accuracy: 0.937500\n",
      "Epoch:037 lr: 0.001000 Step:0050 Train Loss: 1.041831 Train Accuracy: 0.861520\n",
      "Epoch:037 Test Loss: 1.032168 Test Accuracy: 0.870924\n",
      "Epoch:038 lr: 0.001000 Step:0000 Train Loss: 1.117352 Train Accuracy: 0.781250\n",
      "Epoch:038 lr: 0.001000 Step:0050 Train Loss: 1.059505 Train Accuracy: 0.838235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:038 Test Loss: 1.033338 Test Accuracy: 0.873641\n",
      "Epoch:039 lr: 0.001000 Step:0000 Train Loss: 1.097348 Train Accuracy: 0.812500\n",
      "Epoch:039 lr: 0.001000 Step:0050 Train Loss: 1.055134 Train Accuracy: 0.848652\n",
      "Epoch:039 Test Loss: 1.021390 Test Accuracy: 0.884511\n",
      "Epoch:040 lr: 0.001000 Step:0000 Train Loss: 1.039779 Train Accuracy: 0.875000\n",
      "Epoch:040 lr: 0.001000 Step:0050 Train Loss: 1.068231 Train Accuracy: 0.835172\n",
      "Epoch:040 Test Loss: 1.043418 Test Accuracy: 0.847826\n",
      "Epoch:041 lr: 0.001000 Step:0000 Train Loss: 1.050797 Train Accuracy: 0.843750\n",
      "Epoch:041 lr: 0.001000 Step:0050 Train Loss: 1.066633 Train Accuracy: 0.835172\n",
      "Epoch:041 Test Loss: 1.023838 Test Accuracy: 0.877717\n",
      "Epoch:042 lr: 0.001000 Step:0000 Train Loss: 1.002593 Train Accuracy: 0.906250\n",
      "Epoch:042 lr: 0.001000 Step:0050 Train Loss: 1.033186 Train Accuracy: 0.870711\n",
      "Epoch:042 Test Loss: 1.053599 Test Accuracy: 0.845109\n",
      "Epoch:043 lr: 0.001000 Step:0000 Train Loss: 1.069809 Train Accuracy: 0.843750\n",
      "Epoch:043 lr: 0.001000 Step:0050 Train Loss: 1.036750 Train Accuracy: 0.868260\n",
      "Epoch:043 Test Loss: 1.047428 Test Accuracy: 0.853261\n",
      "Epoch:044 lr: 0.001000 Step:0000 Train Loss: 1.110370 Train Accuracy: 0.781250\n",
      "Epoch:044 lr: 0.001000 Step:0050 Train Loss: 1.059788 Train Accuracy: 0.838235\n",
      "Epoch:044 Test Loss: 1.072270 Test Accuracy: 0.832880\n",
      "Epoch:045 lr: 0.001000 Step:0000 Train Loss: 1.029120 Train Accuracy: 0.875000\n",
      "Epoch:045 lr: 0.001000 Step:0050 Train Loss: 1.061701 Train Accuracy: 0.838848\n",
      "Epoch:045 Test Loss: 1.050778 Test Accuracy: 0.849185\n",
      "Epoch:046 lr: 0.001000 Step:0000 Train Loss: 1.002765 Train Accuracy: 0.906250\n",
      "Epoch:046 lr: 0.001000 Step:0050 Train Loss: 1.045006 Train Accuracy: 0.861520\n",
      "Epoch:046 Test Loss: 1.031203 Test Accuracy: 0.870924\n",
      "Epoch:047 lr: 0.001000 Step:0000 Train Loss: 1.026834 Train Accuracy: 0.875000\n",
      "Epoch:047 lr: 0.001000 Step:0050 Train Loss: 1.040126 Train Accuracy: 0.861520\n",
      "Epoch:047 Test Loss: 1.039419 Test Accuracy: 0.868207\n",
      "Epoch:048 lr: 0.001000 Step:0000 Train Loss: 0.977156 Train Accuracy: 0.937500\n",
      "Epoch:048 lr: 0.001000 Step:0050 Train Loss: 1.051539 Train Accuracy: 0.854167\n",
      "Epoch:048 Test Loss: 1.024285 Test Accuracy: 0.887228\n",
      "Epoch:049 lr: 0.001000 Step:0000 Train Loss: 0.994374 Train Accuracy: 0.906250\n",
      "Epoch:049 lr: 0.001000 Step:0050 Train Loss: 1.043836 Train Accuracy: 0.860294\n",
      "Epoch:049 Test Loss: 1.040522 Test Accuracy: 0.862772\n",
      "Epoch:050 lr: 0.001000 Step:0000 Train Loss: 1.023158 Train Accuracy: 0.875000\n",
      "Epoch:050 lr: 0.001000 Step:0050 Train Loss: 1.057120 Train Accuracy: 0.843137\n",
      "Epoch:050 Test Loss: 1.031494 Test Accuracy: 0.869565\n",
      "Epoch:051 lr: 0.001000 Step:0000 Train Loss: 1.024875 Train Accuracy: 0.875000\n",
      "Epoch:051 lr: 0.001000 Step:0050 Train Loss: 1.037076 Train Accuracy: 0.866422\n",
      "Epoch:051 Test Loss: 1.059238 Test Accuracy: 0.835598\n",
      "Epoch:052 lr: 0.001000 Step:0000 Train Loss: 1.064245 Train Accuracy: 0.843750\n",
      "Epoch:052 lr: 0.001000 Step:0050 Train Loss: 1.038046 Train Accuracy: 0.863971\n",
      "Epoch:052 Test Loss: 1.029434 Test Accuracy: 0.872283\n",
      "Epoch:053 lr: 0.001000 Step:0000 Train Loss: 1.103031 Train Accuracy: 0.781250\n",
      "Epoch:053 lr: 0.001000 Step:0050 Train Loss: 1.031906 Train Accuracy: 0.870098\n",
      "Epoch:053 Test Loss: 1.035774 Test Accuracy: 0.866848\n",
      "Epoch:054 lr: 0.001000 Step:0000 Train Loss: 1.106137 Train Accuracy: 0.781250\n",
      "Epoch:054 lr: 0.001000 Step:0050 Train Loss: 1.038748 Train Accuracy: 0.861520\n",
      "Epoch:054 Test Loss: 1.045812 Test Accuracy: 0.854620\n",
      "Epoch:055 lr: 0.001000 Step:0000 Train Loss: 0.975609 Train Accuracy: 0.937500\n",
      "Epoch:055 lr: 0.001000 Step:0050 Train Loss: 1.052022 Train Accuracy: 0.849877\n",
      "Epoch:055 Test Loss: 1.044179 Test Accuracy: 0.860054\n",
      "Epoch:056 lr: 0.001000 Step:0000 Train Loss: 1.049368 Train Accuracy: 0.875000\n",
      "Epoch:056 lr: 0.001000 Step:0050 Train Loss: 1.039514 Train Accuracy: 0.865196\n",
      "Epoch:056 Test Loss: 1.029484 Test Accuracy: 0.875000\n",
      "Epoch:057 lr: 0.001000 Step:0000 Train Loss: 1.160933 Train Accuracy: 0.750000\n",
      "Epoch:057 lr: 0.001000 Step:0050 Train Loss: 1.028937 Train Accuracy: 0.873775\n",
      "Epoch:057 Test Loss: 1.046104 Test Accuracy: 0.855978\n",
      "Epoch:058 lr: 0.001000 Step:0000 Train Loss: 1.014279 Train Accuracy: 0.875000\n",
      "Epoch:058 lr: 0.001000 Step:0050 Train Loss: 1.038382 Train Accuracy: 0.861520\n",
      "Epoch:058 Test Loss: 1.011864 Test Accuracy: 0.892663\n",
      "Epoch:059 lr: 0.001000 Step:0000 Train Loss: 1.027107 Train Accuracy: 0.875000\n",
      "Epoch:059 lr: 0.001000 Step:0050 Train Loss: 1.035563 Train Accuracy: 0.870711\n",
      "Epoch:059 Test Loss: 1.029913 Test Accuracy: 0.873641\n",
      "Epoch:060 lr: 0.001000 Step:0000 Train Loss: 1.066256 Train Accuracy: 0.812500\n",
      "Epoch:060 lr: 0.001000 Step:0050 Train Loss: 1.061218 Train Accuracy: 0.845588\n",
      "Epoch:060 Test Loss: 1.047988 Test Accuracy: 0.858696\n",
      "Epoch:061 lr: 0.001000 Step:0000 Train Loss: 1.029128 Train Accuracy: 0.875000\n",
      "Epoch:061 lr: 0.001000 Step:0050 Train Loss: 1.061443 Train Accuracy: 0.836397\n",
      "Epoch:061 Test Loss: 1.031051 Test Accuracy: 0.870924\n",
      "Epoch:062 lr: 0.001000 Step:0000 Train Loss: 1.012565 Train Accuracy: 0.906250\n",
      "Epoch:062 lr: 0.001000 Step:0050 Train Loss: 1.050803 Train Accuracy: 0.851103\n",
      "Epoch:062 Test Loss: 1.055734 Test Accuracy: 0.839674\n",
      "Epoch:063 lr: 0.001000 Step:0000 Train Loss: 1.024912 Train Accuracy: 0.875000\n",
      "Epoch:063 lr: 0.001000 Step:0050 Train Loss: 1.062794 Train Accuracy: 0.840074\n",
      "Epoch:063 Test Loss: 1.038298 Test Accuracy: 0.861413\n",
      "Epoch:064 lr: 0.001000 Step:0000 Train Loss: 0.992390 Train Accuracy: 0.906250\n",
      "Epoch:064 lr: 0.001000 Step:0050 Train Loss: 1.017802 Train Accuracy: 0.882966\n",
      "Epoch:064 Test Loss: 1.046575 Test Accuracy: 0.855978\n",
      "Epoch:065 lr: 0.001000 Step:0000 Train Loss: 0.983181 Train Accuracy: 0.906250\n",
      "Epoch:065 lr: 0.001000 Step:0050 Train Loss: 1.040514 Train Accuracy: 0.862132\n",
      "Epoch:065 Test Loss: 1.056440 Test Accuracy: 0.849185\n",
      "Epoch:066 lr: 0.001000 Step:0000 Train Loss: 1.058818 Train Accuracy: 0.875000\n",
      "Epoch:066 lr: 0.001000 Step:0050 Train Loss: 1.040054 Train Accuracy: 0.864583\n",
      "Epoch:066 Test Loss: 1.049333 Test Accuracy: 0.853261\n",
      "Epoch:067 lr: 0.001000 Step:0000 Train Loss: 1.123306 Train Accuracy: 0.781250\n",
      "Epoch:067 lr: 0.001000 Step:0050 Train Loss: 1.062359 Train Accuracy: 0.837010\n",
      "Epoch:067 Test Loss: 1.049673 Test Accuracy: 0.854620\n",
      "Epoch:068 lr: 0.001000 Step:0000 Train Loss: 1.060855 Train Accuracy: 0.843750\n",
      "Epoch:068 lr: 0.001000 Step:0050 Train Loss: 1.036763 Train Accuracy: 0.866422\n",
      "Epoch:068 Test Loss: 1.015556 Test Accuracy: 0.888587\n",
      "Epoch:069 lr: 0.001000 Step:0000 Train Loss: 1.021221 Train Accuracy: 0.875000\n",
      "Epoch:069 lr: 0.001000 Step:0050 Train Loss: 1.033554 Train Accuracy: 0.872549\n",
      "Epoch:069 Test Loss: 1.031820 Test Accuracy: 0.872283\n",
      "Epoch:070 lr: 0.001000 Step:0000 Train Loss: 1.094252 Train Accuracy: 0.781250\n",
      "Epoch:070 lr: 0.001000 Step:0050 Train Loss: 1.017301 Train Accuracy: 0.885417\n",
      "Epoch:070 Test Loss: 1.048352 Test Accuracy: 0.847826\n",
      "Epoch:071 lr: 0.001000 Step:0000 Train Loss: 1.032743 Train Accuracy: 0.875000\n",
      "Epoch:071 lr: 0.001000 Step:0050 Train Loss: 1.038131 Train Accuracy: 0.862132\n",
      "Epoch:071 Test Loss: 1.014069 Test Accuracy: 0.892663\n",
      "Epoch:072 lr: 0.001000 Step:0000 Train Loss: 1.054746 Train Accuracy: 0.875000\n",
      "Epoch:072 lr: 0.001000 Step:0050 Train Loss: 1.039507 Train Accuracy: 0.866422\n",
      "Epoch:072 Test Loss: 1.024095 Test Accuracy: 0.880435\n",
      "Epoch:073 lr: 0.001000 Step:0000 Train Loss: 0.996469 Train Accuracy: 0.906250\n",
      "Epoch:073 lr: 0.001000 Step:0050 Train Loss: 1.047813 Train Accuracy: 0.856618\n",
      "Epoch:073 Test Loss: 1.037998 Test Accuracy: 0.862772\n",
      "Epoch:074 lr: 0.001000 Step:0000 Train Loss: 1.030059 Train Accuracy: 0.843750\n",
      "Epoch:074 lr: 0.001000 Step:0050 Train Loss: 1.051253 Train Accuracy: 0.851716\n",
      "Epoch:074 Test Loss: 1.045539 Test Accuracy: 0.862772\n",
      "Epoch:075 lr: 0.001000 Step:0000 Train Loss: 1.080144 Train Accuracy: 0.812500\n",
      "Epoch:075 lr: 0.001000 Step:0050 Train Loss: 1.028930 Train Accuracy: 0.875000\n",
      "Epoch:075 Test Loss: 1.044294 Test Accuracy: 0.861413\n",
      "Epoch:076 lr: 0.001000 Step:0000 Train Loss: 1.068539 Train Accuracy: 0.843750\n",
      "Epoch:076 lr: 0.001000 Step:0050 Train Loss: 1.030492 Train Accuracy: 0.871324\n",
      "Epoch:076 Test Loss: 1.043734 Test Accuracy: 0.862772\n",
      "Epoch:077 lr: 0.001000 Step:0000 Train Loss: 1.057666 Train Accuracy: 0.843750\n",
      "Epoch:077 lr: 0.001000 Step:0050 Train Loss: 1.014259 Train Accuracy: 0.886642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:077 Test Loss: 1.029792 Test Accuracy: 0.876359\n",
      "Epoch:078 lr: 0.001000 Step:0000 Train Loss: 1.004582 Train Accuracy: 0.875000\n",
      "Epoch:078 lr: 0.001000 Step:0050 Train Loss: 1.039801 Train Accuracy: 0.865196\n",
      "Epoch:078 Test Loss: 1.014550 Test Accuracy: 0.891304\n",
      "Epoch:079 lr: 0.001000 Step:0000 Train Loss: 1.061561 Train Accuracy: 0.812500\n",
      "Epoch:079 lr: 0.001000 Step:0050 Train Loss: 1.020069 Train Accuracy: 0.882353\n",
      "Epoch:079 Test Loss: 1.049336 Test Accuracy: 0.855978\n",
      "Epoch:080 lr: 0.000100 Step:0000 Train Loss: 1.006517 Train Accuracy: 0.906250\n",
      "Epoch:080 lr: 0.000100 Step:0050 Train Loss: 1.021675 Train Accuracy: 0.883578\n",
      "Epoch:080 Test Loss: 1.021734 Test Accuracy: 0.879076\n",
      "Epoch:081 lr: 0.000100 Step:0000 Train Loss: 0.950644 Train Accuracy: 0.937500\n",
      "Epoch:081 lr: 0.000100 Step:0050 Train Loss: 0.998286 Train Accuracy: 0.905025\n",
      "Epoch:081 Test Loss: 1.009395 Test Accuracy: 0.894022\n",
      "Epoch:082 lr: 0.000100 Step:0000 Train Loss: 0.976703 Train Accuracy: 0.937500\n",
      "Epoch:082 lr: 0.000100 Step:0050 Train Loss: 0.990607 Train Accuracy: 0.911765\n",
      "Epoch:082 Test Loss: 0.997973 Test Accuracy: 0.903533\n",
      "Epoch:083 lr: 0.000100 Step:0000 Train Loss: 1.126102 Train Accuracy: 0.781250\n",
      "Epoch:083 lr: 0.000100 Step:0050 Train Loss: 1.003065 Train Accuracy: 0.899510\n",
      "Epoch:083 Test Loss: 1.003935 Test Accuracy: 0.898098\n",
      "Epoch:084 lr: 0.000100 Step:0000 Train Loss: 1.047773 Train Accuracy: 0.875000\n",
      "Epoch:084 lr: 0.000100 Step:0050 Train Loss: 0.984482 Train Accuracy: 0.919118\n",
      "Epoch:084 Test Loss: 1.002633 Test Accuracy: 0.902174\n",
      "Epoch:085 lr: 0.000100 Step:0000 Train Loss: 1.095959 Train Accuracy: 0.812500\n",
      "Epoch:085 lr: 0.000100 Step:0050 Train Loss: 0.994318 Train Accuracy: 0.907475\n",
      "Epoch:085 Test Loss: 1.000248 Test Accuracy: 0.900815\n",
      "Epoch:086 lr: 0.000100 Step:0000 Train Loss: 0.917489 Train Accuracy: 1.000000\n",
      "Epoch:086 lr: 0.000100 Step:0050 Train Loss: 0.987889 Train Accuracy: 0.915441\n",
      "Epoch:086 Test Loss: 1.001065 Test Accuracy: 0.903533\n",
      "Epoch:087 lr: 0.000100 Step:0000 Train Loss: 0.904843 Train Accuracy: 1.000000\n",
      "Epoch:087 lr: 0.000100 Step:0050 Train Loss: 0.985357 Train Accuracy: 0.921569\n",
      "Epoch:087 Test Loss: 0.998509 Test Accuracy: 0.902174\n",
      "Epoch:088 lr: 0.000100 Step:0000 Train Loss: 1.004876 Train Accuracy: 0.906250\n",
      "Epoch:088 lr: 0.000100 Step:0050 Train Loss: 0.978206 Train Accuracy: 0.927696\n",
      "Epoch:088 Test Loss: 0.996526 Test Accuracy: 0.908967\n",
      "Epoch:089 lr: 0.000100 Step:0000 Train Loss: 0.973599 Train Accuracy: 0.937500\n",
      "Epoch:089 lr: 0.000100 Step:0050 Train Loss: 0.981380 Train Accuracy: 0.920343\n",
      "Epoch:089 Test Loss: 0.996404 Test Accuracy: 0.906250\n",
      "Epoch:090 lr: 0.000100 Step:0000 Train Loss: 0.953616 Train Accuracy: 0.937500\n",
      "Epoch:090 lr: 0.000100 Step:0050 Train Loss: 0.984475 Train Accuracy: 0.916054\n",
      "Epoch:090 Test Loss: 0.995550 Test Accuracy: 0.907609\n",
      "Epoch:091 lr: 0.000100 Step:0000 Train Loss: 0.935497 Train Accuracy: 0.968750\n",
      "Epoch:091 lr: 0.000100 Step:0050 Train Loss: 0.983209 Train Accuracy: 0.918505\n",
      "Epoch:091 Test Loss: 0.995343 Test Accuracy: 0.906250\n",
      "Epoch:092 lr: 0.000100 Step:0000 Train Loss: 0.959532 Train Accuracy: 0.937500\n",
      "Epoch:092 lr: 0.000100 Step:0050 Train Loss: 0.982686 Train Accuracy: 0.919730\n",
      "Epoch:092 Test Loss: 0.993844 Test Accuracy: 0.908967\n",
      "Epoch:093 lr: 0.000100 Step:0000 Train Loss: 0.965626 Train Accuracy: 0.937500\n",
      "Epoch:093 lr: 0.000100 Step:0050 Train Loss: 0.971045 Train Accuracy: 0.931373\n",
      "Epoch:093 Test Loss: 0.994681 Test Accuracy: 0.908967\n",
      "Epoch:094 lr: 0.000100 Step:0000 Train Loss: 1.014194 Train Accuracy: 0.875000\n",
      "Epoch:094 lr: 0.000100 Step:0050 Train Loss: 0.969781 Train Accuracy: 0.931985\n",
      "Epoch:094 Test Loss: 0.996503 Test Accuracy: 0.906250\n",
      "Epoch:095 lr: 0.000100 Step:0000 Train Loss: 0.939422 Train Accuracy: 0.968750\n",
      "Epoch:095 lr: 0.000100 Step:0050 Train Loss: 0.967383 Train Accuracy: 0.936275\n",
      "Epoch:095 Test Loss: 0.991477 Test Accuracy: 0.911685\n",
      "Epoch:096 lr: 0.000100 Step:0000 Train Loss: 0.929987 Train Accuracy: 0.968750\n",
      "Epoch:096 lr: 0.000100 Step:0050 Train Loss: 0.965835 Train Accuracy: 0.936887\n",
      "Epoch:096 Test Loss: 1.000105 Test Accuracy: 0.902174\n",
      "Epoch:097 lr: 0.000100 Step:0000 Train Loss: 0.914011 Train Accuracy: 1.000000\n",
      "Epoch:097 lr: 0.000100 Step:0050 Train Loss: 0.975277 Train Accuracy: 0.927696\n",
      "Epoch:097 Test Loss: 0.993387 Test Accuracy: 0.906250\n",
      "Epoch:098 lr: 0.000100 Step:0000 Train Loss: 1.001282 Train Accuracy: 0.906250\n",
      "Epoch:098 lr: 0.000100 Step:0050 Train Loss: 0.969331 Train Accuracy: 0.935662\n",
      "Epoch:098 Test Loss: 0.997213 Test Accuracy: 0.907609\n",
      "Epoch:099 lr: 0.000100 Step:0000 Train Loss: 0.982532 Train Accuracy: 0.906250\n",
      "Epoch:099 lr: 0.000100 Step:0050 Train Loss: 0.968700 Train Accuracy: 0.935662\n",
      "Epoch:099 Test Loss: 0.991249 Test Accuracy: 0.911685\n",
      "Epoch:100 lr: 0.000100 Step:0000 Train Loss: 1.073984 Train Accuracy: 0.812500\n",
      "Epoch:100 lr: 0.000100 Step:0050 Train Loss: 0.963946 Train Accuracy: 0.938113\n",
      "Epoch:100 Test Loss: 0.985486 Test Accuracy: 0.919837\n",
      "Epoch:101 lr: 0.000100 Step:0000 Train Loss: 0.962437 Train Accuracy: 0.937500\n",
      "Epoch:101 lr: 0.000100 Step:0050 Train Loss: 0.974324 Train Accuracy: 0.930147\n",
      "Epoch:101 Test Loss: 0.988470 Test Accuracy: 0.914402\n",
      "Epoch:102 lr: 0.000100 Step:0000 Train Loss: 0.928187 Train Accuracy: 0.968750\n",
      "Epoch:102 lr: 0.000100 Step:0050 Train Loss: 0.974466 Train Accuracy: 0.931373\n",
      "Epoch:102 Test Loss: 0.988654 Test Accuracy: 0.915761\n",
      "Epoch:103 lr: 0.000100 Step:0000 Train Loss: 0.970876 Train Accuracy: 0.937500\n",
      "Epoch:103 lr: 0.000100 Step:0050 Train Loss: 0.969686 Train Accuracy: 0.933824\n",
      "Epoch:103 Test Loss: 0.988458 Test Accuracy: 0.914402\n",
      "Epoch:104 lr: 0.000100 Step:0000 Train Loss: 0.907113 Train Accuracy: 1.000000\n",
      "Epoch:104 lr: 0.000100 Step:0050 Train Loss: 0.968697 Train Accuracy: 0.937500\n",
      "Epoch:104 Test Loss: 0.989505 Test Accuracy: 0.917120\n",
      "Epoch:105 lr: 0.000100 Step:0000 Train Loss: 0.905018 Train Accuracy: 1.000000\n",
      "Epoch:105 lr: 0.000100 Step:0050 Train Loss: 0.964619 Train Accuracy: 0.938725\n",
      "Epoch:105 Test Loss: 0.988922 Test Accuracy: 0.915761\n",
      "Epoch:106 lr: 0.000100 Step:0000 Train Loss: 0.974044 Train Accuracy: 0.906250\n",
      "Epoch:106 lr: 0.000100 Step:0050 Train Loss: 0.966761 Train Accuracy: 0.936275\n",
      "Epoch:106 Test Loss: 0.991993 Test Accuracy: 0.910326\n",
      "Epoch:107 lr: 0.000100 Step:0000 Train Loss: 1.070100 Train Accuracy: 0.843750\n",
      "Epoch:107 lr: 0.000100 Step:0050 Train Loss: 0.966454 Train Accuracy: 0.938113\n",
      "Epoch:107 Test Loss: 0.989720 Test Accuracy: 0.910326\n",
      "Epoch:108 lr: 0.000100 Step:0000 Train Loss: 0.908497 Train Accuracy: 1.000000\n",
      "Epoch:108 lr: 0.000100 Step:0050 Train Loss: 0.964435 Train Accuracy: 0.938725\n",
      "Epoch:108 Test Loss: 0.988536 Test Accuracy: 0.915761\n",
      "Epoch:109 lr: 0.000100 Step:0000 Train Loss: 0.938123 Train Accuracy: 0.968750\n",
      "Epoch:109 lr: 0.000100 Step:0050 Train Loss: 0.948306 Train Accuracy: 0.954657\n",
      "Epoch:109 Test Loss: 0.993234 Test Accuracy: 0.911685\n",
      "Epoch:110 lr: 0.000100 Step:0000 Train Loss: 0.941024 Train Accuracy: 0.968750\n",
      "Epoch:110 lr: 0.000100 Step:0050 Train Loss: 0.960347 Train Accuracy: 0.943627\n",
      "Epoch:110 Test Loss: 0.989078 Test Accuracy: 0.914402\n",
      "Epoch:111 lr: 0.000100 Step:0000 Train Loss: 0.956129 Train Accuracy: 0.937500\n",
      "Epoch:111 lr: 0.000100 Step:0050 Train Loss: 0.962436 Train Accuracy: 0.943015\n",
      "Epoch:111 Test Loss: 0.982154 Test Accuracy: 0.922554\n",
      "Epoch:112 lr: 0.000100 Step:0000 Train Loss: 0.942710 Train Accuracy: 0.968750\n",
      "Epoch:112 lr: 0.000100 Step:0050 Train Loss: 0.962417 Train Accuracy: 0.941789\n",
      "Epoch:112 Test Loss: 0.987242 Test Accuracy: 0.915761\n",
      "Epoch:113 lr: 0.000100 Step:0000 Train Loss: 0.967645 Train Accuracy: 0.937500\n",
      "Epoch:113 lr: 0.000100 Step:0050 Train Loss: 0.962919 Train Accuracy: 0.942402\n",
      "Epoch:113 Test Loss: 0.988504 Test Accuracy: 0.917120\n",
      "Epoch:114 lr: 0.000100 Step:0000 Train Loss: 0.950384 Train Accuracy: 0.937500\n",
      "Epoch:114 lr: 0.000100 Step:0050 Train Loss: 0.959805 Train Accuracy: 0.944240\n",
      "Epoch:114 Test Loss: 0.993871 Test Accuracy: 0.911685\n",
      "Epoch:115 lr: 0.000100 Step:0000 Train Loss: 0.904838 Train Accuracy: 1.000000\n",
      "Epoch:115 lr: 0.000100 Step:0050 Train Loss: 0.951042 Train Accuracy: 0.954657\n",
      "Epoch:115 Test Loss: 0.982823 Test Accuracy: 0.918478\n",
      "Epoch:116 lr: 0.000100 Step:0000 Train Loss: 0.960076 Train Accuracy: 0.937500\n",
      "Epoch:116 lr: 0.000100 Step:0050 Train Loss: 0.964841 Train Accuracy: 0.939338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:116 Test Loss: 0.987262 Test Accuracy: 0.917120\n",
      "Epoch:117 lr: 0.000100 Step:0000 Train Loss: 0.965612 Train Accuracy: 0.937500\n",
      "Epoch:117 lr: 0.000100 Step:0050 Train Loss: 0.955473 Train Accuracy: 0.949755\n",
      "Epoch:117 Test Loss: 0.989710 Test Accuracy: 0.913043\n",
      "Epoch:118 lr: 0.000100 Step:0000 Train Loss: 0.965044 Train Accuracy: 0.937500\n",
      "Epoch:118 lr: 0.000100 Step:0050 Train Loss: 0.957528 Train Accuracy: 0.947917\n",
      "Epoch:118 Test Loss: 0.990258 Test Accuracy: 0.915761\n",
      "Epoch:119 lr: 0.000100 Step:0000 Train Loss: 0.932154 Train Accuracy: 0.968750\n",
      "Epoch:119 lr: 0.000100 Step:0050 Train Loss: 0.964114 Train Accuracy: 0.939951\n",
      "Epoch:119 Test Loss: 0.986111 Test Accuracy: 0.918478\n",
      "Epoch:120 lr: 0.000100 Step:0000 Train Loss: 0.904872 Train Accuracy: 1.000000\n",
      "Epoch:120 lr: 0.000100 Step:0050 Train Loss: 0.949311 Train Accuracy: 0.955882\n",
      "Epoch:120 Test Loss: 0.991242 Test Accuracy: 0.914402\n",
      "Epoch:121 lr: 0.000100 Step:0000 Train Loss: 0.996061 Train Accuracy: 0.906250\n",
      "Epoch:121 lr: 0.000100 Step:0050 Train Loss: 0.951976 Train Accuracy: 0.953431\n",
      "Epoch:121 Test Loss: 0.989268 Test Accuracy: 0.914402\n",
      "Epoch:122 lr: 0.000100 Step:0000 Train Loss: 0.934757 Train Accuracy: 0.968750\n",
      "Epoch:122 lr: 0.000100 Step:0050 Train Loss: 0.953580 Train Accuracy: 0.948529\n",
      "Epoch:122 Test Loss: 0.993463 Test Accuracy: 0.913043\n",
      "Epoch:123 lr: 0.000100 Step:0000 Train Loss: 0.971021 Train Accuracy: 0.906250\n",
      "Epoch:123 lr: 0.000100 Step:0050 Train Loss: 0.951870 Train Accuracy: 0.953431\n",
      "Epoch:123 Test Loss: 0.999083 Test Accuracy: 0.904891\n",
      "Epoch:124 lr: 0.000100 Step:0000 Train Loss: 1.007460 Train Accuracy: 0.875000\n",
      "Epoch:124 lr: 0.000100 Step:0050 Train Loss: 0.957065 Train Accuracy: 0.944853\n",
      "Epoch:124 Test Loss: 0.995729 Test Accuracy: 0.906250\n",
      "Epoch:125 lr: 0.000100 Step:0000 Train Loss: 1.000103 Train Accuracy: 0.906250\n",
      "Epoch:125 lr: 0.000100 Step:0050 Train Loss: 0.954518 Train Accuracy: 0.949142\n",
      "Epoch:125 Test Loss: 0.992780 Test Accuracy: 0.911685\n",
      "Epoch:126 lr: 0.000100 Step:0000 Train Loss: 0.905209 Train Accuracy: 1.000000\n",
      "Epoch:126 lr: 0.000100 Step:0050 Train Loss: 0.950337 Train Accuracy: 0.952819\n",
      "Epoch:126 Test Loss: 0.994748 Test Accuracy: 0.908967\n",
      "Epoch:127 lr: 0.000100 Step:0000 Train Loss: 0.933058 Train Accuracy: 0.968750\n",
      "Epoch:127 lr: 0.000100 Step:0050 Train Loss: 0.951075 Train Accuracy: 0.955882\n",
      "Epoch:127 Test Loss: 0.995053 Test Accuracy: 0.908967\n",
      "Epoch:128 lr: 0.000100 Step:0000 Train Loss: 0.933852 Train Accuracy: 0.968750\n",
      "Epoch:128 lr: 0.000100 Step:0050 Train Loss: 0.959777 Train Accuracy: 0.946078\n",
      "Epoch:128 Test Loss: 0.990481 Test Accuracy: 0.913043\n",
      "Epoch:129 lr: 0.000100 Step:0000 Train Loss: 0.904919 Train Accuracy: 1.000000\n",
      "Epoch:129 lr: 0.000100 Step:0050 Train Loss: 0.955622 Train Accuracy: 0.950368\n",
      "Epoch:129 Test Loss: 0.993408 Test Accuracy: 0.908967\n",
      "Epoch:130 lr: 0.000100 Step:0000 Train Loss: 0.905033 Train Accuracy: 1.000000\n",
      "Epoch:130 lr: 0.000100 Step:0050 Train Loss: 0.956020 Train Accuracy: 0.949142\n",
      "Epoch:130 Test Loss: 0.990220 Test Accuracy: 0.913043\n",
      "Epoch:131 lr: 0.000100 Step:0000 Train Loss: 0.943223 Train Accuracy: 0.968750\n",
      "Epoch:131 lr: 0.000100 Step:0050 Train Loss: 0.947616 Train Accuracy: 0.958946\n",
      "Epoch:131 Test Loss: 0.988791 Test Accuracy: 0.914402\n",
      "Epoch:132 lr: 0.000100 Step:0000 Train Loss: 0.936526 Train Accuracy: 0.968750\n",
      "Epoch:132 lr: 0.000100 Step:0050 Train Loss: 0.950476 Train Accuracy: 0.954657\n",
      "Epoch:132 Test Loss: 0.989380 Test Accuracy: 0.913043\n",
      "Epoch:133 lr: 0.000100 Step:0000 Train Loss: 0.912861 Train Accuracy: 1.000000\n",
      "Epoch:133 lr: 0.000100 Step:0050 Train Loss: 0.947699 Train Accuracy: 0.956495\n",
      "Epoch:133 Test Loss: 0.994968 Test Accuracy: 0.910326\n",
      "Epoch:134 lr: 0.000100 Step:0000 Train Loss: 0.972328 Train Accuracy: 0.937500\n",
      "Epoch:134 lr: 0.000100 Step:0050 Train Loss: 0.950283 Train Accuracy: 0.953431\n",
      "Epoch:134 Test Loss: 0.989989 Test Accuracy: 0.914402\n",
      "Epoch:135 lr: 0.000100 Step:0000 Train Loss: 0.944541 Train Accuracy: 0.968750\n",
      "Epoch:135 lr: 0.000100 Step:0050 Train Loss: 0.953037 Train Accuracy: 0.951593\n",
      "Epoch:135 Test Loss: 0.994746 Test Accuracy: 0.907609\n",
      "Epoch:136 lr: 0.000100 Step:0000 Train Loss: 0.905004 Train Accuracy: 1.000000\n",
      "Epoch:136 lr: 0.000100 Step:0050 Train Loss: 0.947849 Train Accuracy: 0.956495\n",
      "Epoch:136 Test Loss: 0.994829 Test Accuracy: 0.913043\n",
      "Epoch:137 lr: 0.000100 Step:0000 Train Loss: 1.021872 Train Accuracy: 0.875000\n",
      "Epoch:137 lr: 0.000100 Step:0050 Train Loss: 0.955421 Train Accuracy: 0.947917\n",
      "Epoch:137 Test Loss: 0.991150 Test Accuracy: 0.914402\n",
      "Epoch:138 lr: 0.000100 Step:0000 Train Loss: 0.936843 Train Accuracy: 0.968750\n",
      "Epoch:138 lr: 0.000100 Step:0050 Train Loss: 0.939716 Train Accuracy: 0.963848\n",
      "Epoch:138 Test Loss: 0.990630 Test Accuracy: 0.910326\n",
      "Epoch:139 lr: 0.000100 Step:0000 Train Loss: 0.951800 Train Accuracy: 0.937500\n",
      "Epoch:139 lr: 0.000100 Step:0050 Train Loss: 0.944373 Train Accuracy: 0.959559\n",
      "Epoch:139 Test Loss: 0.997558 Test Accuracy: 0.907609\n",
      "Epoch:140 lr: 0.000100 Step:0000 Train Loss: 0.934835 Train Accuracy: 0.968750\n",
      "Epoch:140 lr: 0.000100 Step:0050 Train Loss: 0.941997 Train Accuracy: 0.963848\n",
      "Epoch:140 Test Loss: 0.989591 Test Accuracy: 0.914402\n",
      "Epoch:141 lr: 0.000100 Step:0000 Train Loss: 0.922934 Train Accuracy: 0.968750\n",
      "Epoch:141 lr: 0.000100 Step:0050 Train Loss: 0.942769 Train Accuracy: 0.961397\n",
      "Epoch:141 Test Loss: 0.989462 Test Accuracy: 0.915761\n",
      "Epoch:142 lr: 0.000100 Step:0000 Train Loss: 0.904834 Train Accuracy: 1.000000\n",
      "Epoch:142 lr: 0.000100 Step:0050 Train Loss: 0.942367 Train Accuracy: 0.960784\n",
      "Epoch:142 Test Loss: 0.988678 Test Accuracy: 0.917120\n",
      "Epoch:143 lr: 0.000100 Step:0000 Train Loss: 0.936545 Train Accuracy: 0.968750\n",
      "Epoch:143 lr: 0.000100 Step:0050 Train Loss: 0.948123 Train Accuracy: 0.957108\n",
      "Epoch:143 Test Loss: 0.995385 Test Accuracy: 0.908967\n",
      "Epoch:144 lr: 0.000100 Step:0000 Train Loss: 0.961758 Train Accuracy: 0.937500\n",
      "Epoch:144 lr: 0.000100 Step:0050 Train Loss: 0.953751 Train Accuracy: 0.948529\n",
      "Epoch:144 Test Loss: 0.991798 Test Accuracy: 0.911685\n",
      "Epoch:145 lr: 0.000100 Step:0000 Train Loss: 0.956808 Train Accuracy: 0.937500\n",
      "Epoch:145 lr: 0.000100 Step:0050 Train Loss: 0.946172 Train Accuracy: 0.958946\n",
      "Epoch:145 Test Loss: 0.992514 Test Accuracy: 0.911685\n",
      "Epoch:146 lr: 0.000100 Step:0000 Train Loss: 0.926874 Train Accuracy: 0.968750\n",
      "Epoch:146 lr: 0.000100 Step:0050 Train Loss: 0.945572 Train Accuracy: 0.958946\n",
      "Epoch:146 Test Loss: 0.988716 Test Accuracy: 0.913043\n",
      "Epoch:147 lr: 0.000100 Step:0000 Train Loss: 1.002139 Train Accuracy: 0.875000\n",
      "Epoch:147 lr: 0.000100 Step:0050 Train Loss: 0.943262 Train Accuracy: 0.960172\n",
      "Epoch:147 Test Loss: 0.997457 Test Accuracy: 0.902174\n",
      "Epoch:148 lr: 0.000100 Step:0000 Train Loss: 0.905100 Train Accuracy: 1.000000\n",
      "Epoch:148 lr: 0.000100 Step:0050 Train Loss: 0.940483 Train Accuracy: 0.964461\n",
      "Epoch:148 Test Loss: 0.987256 Test Accuracy: 0.911685\n",
      "Epoch:149 lr: 0.000100 Step:0000 Train Loss: 0.921181 Train Accuracy: 1.000000\n",
      "Epoch:149 lr: 0.000100 Step:0050 Train Loss: 0.939617 Train Accuracy: 0.965074\n",
      "Epoch:149 Test Loss: 0.992410 Test Accuracy: 0.914402\n",
      "Epoch:150 lr: 0.000100 Step:0000 Train Loss: 1.013465 Train Accuracy: 0.875000\n",
      "Epoch:150 lr: 0.000100 Step:0050 Train Loss: 0.941421 Train Accuracy: 0.962623\n",
      "Epoch:150 Test Loss: 0.990525 Test Accuracy: 0.908967\n",
      "Epoch:151 lr: 0.000100 Step:0000 Train Loss: 0.930786 Train Accuracy: 0.968750\n",
      "Epoch:151 lr: 0.000100 Step:0050 Train Loss: 0.936216 Train Accuracy: 0.968750\n",
      "Epoch:151 Test Loss: 0.993404 Test Accuracy: 0.908967\n",
      "Epoch:152 lr: 0.000100 Step:0000 Train Loss: 0.941390 Train Accuracy: 0.968750\n",
      "Epoch:152 lr: 0.000100 Step:0050 Train Loss: 0.942211 Train Accuracy: 0.963235\n",
      "Epoch:152 Test Loss: 0.991111 Test Accuracy: 0.911685\n",
      "Epoch:153 lr: 0.000100 Step:0000 Train Loss: 0.923148 Train Accuracy: 0.968750\n",
      "Epoch:153 lr: 0.000100 Step:0050 Train Loss: 0.933071 Train Accuracy: 0.972426\n",
      "Epoch:153 Test Loss: 0.993911 Test Accuracy: 0.913043\n",
      "Epoch:154 lr: 0.000100 Step:0000 Train Loss: 0.932240 Train Accuracy: 0.968750\n",
      "Epoch:154 lr: 0.000100 Step:0050 Train Loss: 0.949575 Train Accuracy: 0.955270\n",
      "Epoch:154 Test Loss: 0.990704 Test Accuracy: 0.911685\n",
      "Epoch:155 lr: 0.000100 Step:0000 Train Loss: 0.969411 Train Accuracy: 0.937500\n",
      "Epoch:155 lr: 0.000100 Step:0050 Train Loss: 0.935620 Train Accuracy: 0.969975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:155 Test Loss: 0.991812 Test Accuracy: 0.913043\n",
      "Epoch:156 lr: 0.000100 Step:0000 Train Loss: 0.959727 Train Accuracy: 0.937500\n",
      "Epoch:156 lr: 0.000100 Step:0050 Train Loss: 0.943245 Train Accuracy: 0.961397\n",
      "Epoch:156 Test Loss: 0.991206 Test Accuracy: 0.913043\n",
      "Epoch:157 lr: 0.000100 Step:0000 Train Loss: 0.904839 Train Accuracy: 1.000000\n",
      "Epoch:157 lr: 0.000100 Step:0050 Train Loss: 0.941686 Train Accuracy: 0.962010\n",
      "Epoch:157 Test Loss: 0.995191 Test Accuracy: 0.908967\n",
      "Epoch:158 lr: 0.000100 Step:0000 Train Loss: 0.934333 Train Accuracy: 0.968750\n",
      "Epoch:158 lr: 0.000100 Step:0050 Train Loss: 0.944178 Train Accuracy: 0.959559\n",
      "Epoch:158 Test Loss: 0.994097 Test Accuracy: 0.907609\n",
      "Epoch:159 lr: 0.000100 Step:0000 Train Loss: 0.948518 Train Accuracy: 0.937500\n",
      "Epoch:159 lr: 0.000100 Step:0050 Train Loss: 0.942315 Train Accuracy: 0.962010\n",
      "Epoch:159 Test Loss: 0.996128 Test Accuracy: 0.907609\n",
      "Epoch:160 lr: 0.000010 Step:0000 Train Loss: 0.904842 Train Accuracy: 1.000000\n",
      "Epoch:160 lr: 0.000010 Step:0050 Train Loss: 0.943811 Train Accuracy: 0.961397\n",
      "Epoch:160 Test Loss: 0.992430 Test Accuracy: 0.908967\n",
      "Epoch:161 lr: 0.000010 Step:0000 Train Loss: 0.904910 Train Accuracy: 1.000000\n",
      "Epoch:161 lr: 0.000010 Step:0050 Train Loss: 0.935681 Train Accuracy: 0.969363\n",
      "Epoch:161 Test Loss: 0.991913 Test Accuracy: 0.911685\n",
      "Epoch:162 lr: 0.000010 Step:0000 Train Loss: 0.985255 Train Accuracy: 0.906250\n",
      "Epoch:162 lr: 0.000010 Step:0050 Train Loss: 0.933289 Train Accuracy: 0.972426\n",
      "Epoch:162 Test Loss: 0.994032 Test Accuracy: 0.910326\n",
      "Epoch:163 lr: 0.000010 Step:0000 Train Loss: 0.904954 Train Accuracy: 1.000000\n",
      "Epoch:163 lr: 0.000010 Step:0050 Train Loss: 0.934033 Train Accuracy: 0.971814\n",
      "Epoch:163 Test Loss: 0.992859 Test Accuracy: 0.907609\n",
      "Epoch:164 lr: 0.000010 Step:0000 Train Loss: 0.904841 Train Accuracy: 1.000000\n",
      "Epoch:164 lr: 0.000010 Step:0050 Train Loss: 0.939124 Train Accuracy: 0.966299\n",
      "Epoch:164 Test Loss: 0.991888 Test Accuracy: 0.908967\n",
      "Epoch:165 lr: 0.000010 Step:0000 Train Loss: 0.932632 Train Accuracy: 0.968750\n",
      "Epoch:165 lr: 0.000010 Step:0050 Train Loss: 0.937414 Train Accuracy: 0.966912\n",
      "Epoch:165 Test Loss: 0.991642 Test Accuracy: 0.913043\n",
      "Epoch:166 lr: 0.000010 Step:0000 Train Loss: 0.969524 Train Accuracy: 0.937500\n",
      "Epoch:166 lr: 0.000010 Step:0050 Train Loss: 0.931570 Train Accuracy: 0.973039\n",
      "Epoch:166 Test Loss: 0.991916 Test Accuracy: 0.913043\n",
      "Epoch:167 lr: 0.000010 Step:0000 Train Loss: 0.962340 Train Accuracy: 0.937500\n",
      "Epoch:167 lr: 0.000010 Step:0050 Train Loss: 0.934944 Train Accuracy: 0.969975\n",
      "Epoch:167 Test Loss: 0.994626 Test Accuracy: 0.910326\n",
      "Epoch:168 lr: 0.000010 Step:0000 Train Loss: 1.007541 Train Accuracy: 0.906250\n",
      "Epoch:168 lr: 0.000010 Step:0050 Train Loss: 0.939394 Train Accuracy: 0.965686\n",
      "Epoch:168 Test Loss: 0.993936 Test Accuracy: 0.908967\n",
      "Epoch:169 lr: 0.000010 Step:0000 Train Loss: 0.945934 Train Accuracy: 0.968750\n",
      "Epoch:169 lr: 0.000010 Step:0050 Train Loss: 0.938721 Train Accuracy: 0.966912\n",
      "Epoch:169 Test Loss: 0.991186 Test Accuracy: 0.911685\n",
      "Epoch:170 lr: 0.000010 Step:0000 Train Loss: 0.976855 Train Accuracy: 0.937500\n",
      "Epoch:170 lr: 0.000010 Step:0050 Train Loss: 0.940987 Train Accuracy: 0.963235\n",
      "Epoch:170 Test Loss: 0.990805 Test Accuracy: 0.913043\n",
      "Epoch:171 lr: 0.000010 Step:0000 Train Loss: 0.932061 Train Accuracy: 0.968750\n",
      "Epoch:171 lr: 0.000010 Step:0050 Train Loss: 0.938617 Train Accuracy: 0.965686\n",
      "Epoch:171 Test Loss: 0.991804 Test Accuracy: 0.910326\n",
      "Epoch:172 lr: 0.000010 Step:0000 Train Loss: 0.961126 Train Accuracy: 0.937500\n",
      "Epoch:172 lr: 0.000010 Step:0050 Train Loss: 0.933972 Train Accuracy: 0.971201\n",
      "Epoch:172 Test Loss: 0.988855 Test Accuracy: 0.915761\n",
      "Epoch:173 lr: 0.000010 Step:0000 Train Loss: 0.904835 Train Accuracy: 1.000000\n",
      "Epoch:173 lr: 0.000010 Step:0050 Train Loss: 0.936955 Train Accuracy: 0.967525\n",
      "Epoch:173 Test Loss: 0.991119 Test Accuracy: 0.910326\n",
      "Epoch:174 lr: 0.000010 Step:0000 Train Loss: 0.933835 Train Accuracy: 0.968750\n",
      "Epoch:174 lr: 0.000010 Step:0050 Train Loss: 0.934161 Train Accuracy: 0.970588\n",
      "Epoch:174 Test Loss: 0.993282 Test Accuracy: 0.906250\n",
      "Epoch:175 lr: 0.000010 Step:0000 Train Loss: 0.906355 Train Accuracy: 1.000000\n",
      "Epoch:175 lr: 0.000010 Step:0050 Train Loss: 0.937169 Train Accuracy: 0.968137\n",
      "Epoch:175 Test Loss: 0.991682 Test Accuracy: 0.910326\n",
      "Epoch:176 lr: 0.000010 Step:0000 Train Loss: 0.929818 Train Accuracy: 0.968750\n",
      "Epoch:176 lr: 0.000010 Step:0050 Train Loss: 0.946107 Train Accuracy: 0.957108\n",
      "Epoch:176 Test Loss: 0.990010 Test Accuracy: 0.914402\n",
      "Epoch:177 lr: 0.000010 Step:0000 Train Loss: 0.904832 Train Accuracy: 1.000000\n",
      "Epoch:177 lr: 0.000010 Step:0050 Train Loss: 0.935062 Train Accuracy: 0.969363\n",
      "Epoch:177 Test Loss: 0.992530 Test Accuracy: 0.910326\n",
      "Epoch:178 lr: 0.000010 Step:0000 Train Loss: 0.990176 Train Accuracy: 0.906250\n",
      "Epoch:178 lr: 0.000010 Step:0050 Train Loss: 0.933351 Train Accuracy: 0.971814\n",
      "Epoch:178 Test Loss: 0.991937 Test Accuracy: 0.913043\n",
      "Epoch:179 lr: 0.000010 Step:0000 Train Loss: 0.985533 Train Accuracy: 0.937500\n",
      "Epoch:179 lr: 0.000010 Step:0050 Train Loss: 0.936601 Train Accuracy: 0.968750\n",
      "Epoch:179 Test Loss: 0.991536 Test Accuracy: 0.908967\n",
      "Epoch:180 lr: 0.000010 Step:0000 Train Loss: 0.947009 Train Accuracy: 0.937500\n",
      "Epoch:180 lr: 0.000010 Step:0050 Train Loss: 0.935558 Train Accuracy: 0.968750\n",
      "Epoch:180 Test Loss: 0.991503 Test Accuracy: 0.913043\n",
      "Epoch:181 lr: 0.000010 Step:0000 Train Loss: 0.967104 Train Accuracy: 0.937500\n",
      "Epoch:181 lr: 0.000010 Step:0050 Train Loss: 0.935942 Train Accuracy: 0.969363\n",
      "Epoch:181 Test Loss: 0.989075 Test Accuracy: 0.913043\n",
      "Epoch:182 lr: 0.000010 Step:0000 Train Loss: 0.985473 Train Accuracy: 0.906250\n",
      "Epoch:182 lr: 0.000010 Step:0050 Train Loss: 0.936161 Train Accuracy: 0.968750\n",
      "Epoch:182 Test Loss: 0.991815 Test Accuracy: 0.911685\n",
      "Epoch:183 lr: 0.000010 Step:0000 Train Loss: 0.964284 Train Accuracy: 0.937500\n",
      "Epoch:183 lr: 0.000010 Step:0050 Train Loss: 0.937561 Train Accuracy: 0.965074\n",
      "Epoch:183 Test Loss: 0.991077 Test Accuracy: 0.908967\n",
      "Epoch:184 lr: 0.000010 Step:0000 Train Loss: 0.904843 Train Accuracy: 1.000000\n",
      "Epoch:184 lr: 0.000010 Step:0050 Train Loss: 0.930532 Train Accuracy: 0.973652\n",
      "Epoch:184 Test Loss: 0.990336 Test Accuracy: 0.913043\n",
      "Epoch:185 lr: 0.000010 Step:0000 Train Loss: 0.940385 Train Accuracy: 0.968750\n",
      "Epoch:185 lr: 0.000010 Step:0050 Train Loss: 0.943249 Train Accuracy: 0.960784\n",
      "Epoch:185 Test Loss: 0.991238 Test Accuracy: 0.914402\n",
      "Epoch:186 lr: 0.000010 Step:0000 Train Loss: 0.905039 Train Accuracy: 1.000000\n",
      "Epoch:186 lr: 0.000010 Step:0050 Train Loss: 0.930326 Train Accuracy: 0.974877\n",
      "Epoch:186 Test Loss: 0.994543 Test Accuracy: 0.906250\n",
      "Epoch:187 lr: 0.000010 Step:0000 Train Loss: 0.914937 Train Accuracy: 1.000000\n",
      "Epoch:187 lr: 0.000010 Step:0050 Train Loss: 0.929908 Train Accuracy: 0.975490\n",
      "Epoch:187 Test Loss: 0.990766 Test Accuracy: 0.908967\n",
      "Epoch:188 lr: 0.000010 Step:0000 Train Loss: 1.023062 Train Accuracy: 0.875000\n",
      "Epoch:188 lr: 0.000010 Step:0050 Train Loss: 0.930973 Train Accuracy: 0.974265\n",
      "Epoch:188 Test Loss: 0.991794 Test Accuracy: 0.911685\n",
      "Epoch:189 lr: 0.000010 Step:0000 Train Loss: 0.908134 Train Accuracy: 1.000000\n",
      "Epoch:189 lr: 0.000010 Step:0050 Train Loss: 0.938718 Train Accuracy: 0.965074\n",
      "Epoch:189 Test Loss: 0.990397 Test Accuracy: 0.911685\n",
      "Epoch:190 lr: 0.000010 Step:0000 Train Loss: 0.905165 Train Accuracy: 1.000000\n",
      "Epoch:190 lr: 0.000010 Step:0050 Train Loss: 0.933181 Train Accuracy: 0.972426\n",
      "Epoch:190 Test Loss: 0.991410 Test Accuracy: 0.908967\n",
      "Epoch:191 lr: 0.000010 Step:0000 Train Loss: 0.907305 Train Accuracy: 1.000000\n",
      "Epoch:191 lr: 0.000010 Step:0050 Train Loss: 0.941170 Train Accuracy: 0.963235\n",
      "Epoch:191 Test Loss: 0.993427 Test Accuracy: 0.906250\n",
      "Epoch:192 lr: 0.000010 Step:0000 Train Loss: 0.961104 Train Accuracy: 0.937500\n",
      "Epoch:192 lr: 0.000010 Step:0050 Train Loss: 0.931643 Train Accuracy: 0.973652\n",
      "Epoch:192 Test Loss: 0.993549 Test Accuracy: 0.908967\n",
      "Epoch:193 lr: 0.000010 Step:0000 Train Loss: 0.905234 Train Accuracy: 1.000000\n",
      "Epoch:193 lr: 0.000010 Step:0050 Train Loss: 0.934485 Train Accuracy: 0.969363\n",
      "Epoch:193 Test Loss: 0.992732 Test Accuracy: 0.910326\n",
      "Epoch:194 lr: 0.000010 Step:0000 Train Loss: 0.936759 Train Accuracy: 0.968750\n",
      "Epoch:194 lr: 0.000010 Step:0050 Train Loss: 0.937474 Train Accuracy: 0.966299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:194 Test Loss: 0.989658 Test Accuracy: 0.913043\n",
      "Epoch:195 lr: 0.000010 Step:0000 Train Loss: 0.953934 Train Accuracy: 0.968750\n",
      "Epoch:195 lr: 0.000010 Step:0050 Train Loss: 0.927976 Train Accuracy: 0.977328\n",
      "Epoch:195 Test Loss: 0.992970 Test Accuracy: 0.911685\n",
      "Epoch:196 lr: 0.000010 Step:0000 Train Loss: 0.930258 Train Accuracy: 0.968750\n",
      "Epoch:196 lr: 0.000010 Step:0050 Train Loss: 0.937631 Train Accuracy: 0.967525\n",
      "Epoch:196 Test Loss: 0.992438 Test Accuracy: 0.910326\n",
      "Epoch:197 lr: 0.000010 Step:0000 Train Loss: 1.029897 Train Accuracy: 0.875000\n",
      "Epoch:197 lr: 0.000010 Step:0050 Train Loss: 0.936089 Train Accuracy: 0.968750\n",
      "Epoch:197 Test Loss: 0.991122 Test Accuracy: 0.908967\n",
      "Epoch:198 lr: 0.000010 Step:0000 Train Loss: 0.975482 Train Accuracy: 0.937500\n",
      "Epoch:198 lr: 0.000010 Step:0050 Train Loss: 0.931136 Train Accuracy: 0.974265\n",
      "Epoch:198 Test Loss: 0.992830 Test Accuracy: 0.908967\n",
      "Epoch:199 lr: 0.000010 Step:0000 Train Loss: 0.949845 Train Accuracy: 0.968750\n",
      "Epoch:199 lr: 0.000010 Step:0050 Train Loss: 0.932983 Train Accuracy: 0.971814\n",
      "Epoch:199 Test Loss: 0.991110 Test Accuracy: 0.911685\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "  running_loss = 0\n",
    "  running_acc = 0\n",
    "  samples = 0\n",
    "  for step, (inputs, labels) in enumerate(train_data_loader):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs,1)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # statistics\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "    running_acc += torch.sum(preds == labels.data)\n",
    "    samples += inputs.size(0)\n",
    "    \n",
    "    if step % show_steps == 0:\n",
    "      loss = running_loss / samples\n",
    "      acc = (running_acc.double() / samples).cpu().numpy()\n",
    "      lr = get_lr(optimizer)\n",
    "      print(\"Epoch:{0:03d} lr: {4:4f} Step:{1:04d} Train Loss: {2:4f} Train Accuracy: {3:4f}\".format(epoch, step, loss, acc, lr))\n",
    "  \n",
    "  # update learning rate      \n",
    "  lr_scheduler.step()\n",
    "    \n",
    "  # validation after every epoch\n",
    "  running_loss = 0\n",
    "  running_acc = 0\n",
    "  with torch.no_grad():\n",
    "    for (inputs, labels) in val_data_loader:\n",
    "      model.eval()\n",
    "      inputs = inputs.to(device)\n",
    "      labels = labels.to(device)\n",
    "      with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_acc += torch.sum(preds == labels.data)\n",
    "\n",
    "    loss = running_loss / len(val_image_dataset)\n",
    "    acc = (running_acc.double() / len(val_image_dataset)).cpu().numpy()\n",
    "    print(\"Epoch:{0:03d} Test Loss: {1:4f} Test Accuracy: {2:4f}\".format(epoch, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baFly1VSGAwF"
   },
   "outputs": [],
   "source": [
    "# save weights\n",
    "torch.save(model.state_dict(), \"flower_mobilenetv2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8-swKip7DmhI"
   },
   "source": [
    "## Inference on Actual Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MobileNetV2:\n\tsize mismatch for classifier.1.weight: copying a param with shape torch.Size([5, 1280]) from checkpoint, the shape in current model is torch.Size([27, 1280]).\n\tsize mismatch for classifier.1.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([27]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c949cf924022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/flower_mobilenetv2.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/.py36env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 777\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MobileNetV2:\n\tsize mismatch for classifier.1.weight: copying a param with shape torch.Size([5, 1280]) from checkpoint, the shape in current model is torch.Size([27, 1280]).\n\tsize mismatch for classifier.1.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([27])."
     ]
    }
   ],
   "source": [
    "classes = sorted([f for f in os.listdir(train_data_path) if not f.startswith('.')])\n",
    "print(classes)\n",
    "imgs = [f for f in os.listdir(data_path) if not f.startswith('.')]\n",
    "base_model = MobileNetV2()\n",
    "base_model.load_state_dict(torch.load('models/mobilenet_v2.pth.tar'), strict=False)\n",
    "model = base_model\n",
    "model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(model.last_channel, 5),\n",
    "    )\n",
    "model.load_state_dict(torch.load('models/flower_mobilenetv2.pth'), strict=True)\n",
    "summary(model.cuda(), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(2):\n",
    "    org_img = cv2.imread('daisy.jpeg.JPG')\n",
    "    img = cv2.resize(org_img, (224,224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    img = img.astype('float32')\n",
    "    img = img / 255\n",
    "    inputs = (img - np.mean(img)) / np.std(img)\n",
    "    inputs = np.transpose(inputs, (2,0,1))\n",
    "    inputs = np.expand_dims(inputs, axis=0)\n",
    "    inputs = torch.tensor(inputs)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        output = model(inputs.cuda())\n",
    "        _, index =  torch.max(output, dim=1)\n",
    "        index = index.cpu().numpy()[0]\n",
    "        dst_path = os.path.join('result2', classes[index])\n",
    "        if not os.path.exists(os.path.join('result2', classes[index])):\n",
    "            os.makedirs(dst_path)\n",
    "        print(index)\n",
    "    print('class:', classes[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "050_deep_learning_presentation.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
